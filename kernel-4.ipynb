{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n#合并两个文档\ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv') #这里读取的是一个读取的Pandas格式\ncombine = [data_train, data_test] #这是一个列表",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#每行缺失值\n#data_train.shape[1] - data_train.count(axis=1)\n#每列缺失值\ndata_train.shape[0] - data_train.count()\n#这里的结果和我在博客看到的不符，但经过检查，结果无误。猜测：官方更改了数据集",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab0472be88ec831b691f74eccc4c18e99d12aade"
      },
      "cell_type": "markdown",
      "source": "发现内有三种缺失值，分别是：Age，Cabin，Embarked。其中Cabin缺失过大，几乎占总体样本但3/4 。Embarked仅有两个。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "257f61d2116b94c2f59d69292941fdb61323458f"
      },
      "cell_type": "code",
      "source": "#查看预测样本集合内缺失\ndata_test.shape[0] - data_test.count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "103cb78f18955945ec825e6ca923d603079d95c2"
      },
      "cell_type": "markdown",
      "source": "发现内有三种缺失，其中年龄缺失、Cabin缺失和训练集相同，但Fare数据内依然有差别。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee5a9fbc87da1dfa50728557dc8693f07fbcc559"
      },
      "cell_type": "code",
      "source": "data_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f705201d61fea2980d30ab873f0b21d7bf93d2e"
      },
      "cell_type": "code",
      "source": "data_train.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0f845f76f64e119ed14c273e97c5e9269aa917d"
      },
      "cell_type": "code",
      "source": "data_train.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01998ac377d0f5854141e91e9c416e718494b1d8"
      },
      "cell_type": "code",
      "source": "#此处记录一个非常强悍的查看缺失值的方法\nimport missingno as msno\nmsno.matrix(data_train,figsize=(14,6))#figsize制图大小",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b004eddd6044256c1393d35edbbf9211d2995bdb"
      },
      "cell_type": "code",
      "source": "data_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aac2a5eee416e69e253792b06bd0fd129befa1d1"
      },
      "cell_type": "markdown",
      "source": "## Age缺失值的处理方法"
    },
    {
      "metadata": {
        "_uuid": "733d90d18f8f27fae8e15c3a521c4e52041040ba"
      },
      "cell_type": "markdown",
      "source": "### 方法一:填充中位数"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc37d4b05d5a00b6b2bd13692fbac48367189dd9"
      },
      "cell_type": "code",
      "source": "#方法一：填充中位数\nage_median = data_train.Age.median()\nage_median",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89abd1f000e29010ba08615d1c06c3337e82df5d"
      },
      "cell_type": "markdown",
      "source": "### 方法二：根据每个人对应的称谓中位数填充，更加准确，如miss和Mrs可能年龄不同"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd412baabfa1ecf6bb50c9ccaddd851a89e9a306"
      },
      "cell_type": "code",
      "source": "#方法二：根据每个人对应的称谓中位数填充，更加准确，如miss和Mrs可能年龄不同\n#1.检查称谓\ncount = 0 #count the number of names without \"Mr./Miss./Master./Dr./Mrs.\"\ndef check_if_the_name_including_reguler(dataset,count):\n    for data in dataset.Name:\n        if (\"Mr.\" not in data) & (\"Miss.\" not in data) & (\"Master.\" not in data) & (\"Dr.\" not in data) & (\"Mrs.\" not in data):\n            print(data)\n            count = count +1\n    print(\"\\nthe number of names without 'Mr./Miss./Master./Dr./Mrs.' is \" + str(count))\n    return count\n\ncheck_if_the_name_including_reguler(data_train,count)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "632d38cd5d972a6fe12e99d585f04c33c30ffe9e"
      },
      "cell_type": "markdown",
      "source": "结果可见，仅20人没有带有相关称谓。根据幸存者手册（https://www.encyclopedia-titanica.org/titanic-survivor/lady-duff-gordon.html） 其中部分是爵、牧师等特殊身份的人。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c9775ed4e3d0fc650827bf00567497313322874"
      },
      "cell_type": "code",
      "source": "#统计每种称谓的平均年龄\nage_in = []   #Mr./Miss./Master./Dr./Mrs.\nfor i in range(0,5):\n    age_in.insert(0,[0,0])\ndef count_every_call_mid(data_train,age_in):\n    #data_train.ix[\"Miss.\" in data_train.Name]\n    for data in data_train.index:\n        #print(data_train.loc[data,\"Name\"])\n        if \"Mr.\" in data_train.loc[data,\"Name\"]:\n            if not math.isnan(data_train.loc[data,\"Age\"]) :\n                age_in[0][0]+=data_train.loc[data,\"Age\"]\n                age_in[0][1]+=1\n        elif \"Miss.\" in data_train.loc[data,\"Name\"]:\n            if not math.isnan(data_train.loc[data,\"Age\"]) :\n                age_in[1][0]+=data_train.loc[data,\"Age\"]\n                age_in[1][1]+=1\n        elif \"Master.\" in data_train.loc[data,\"Name\"]:\n            if not math.isnan(data_train.loc[data,\"Age\"]) :\n                age_in[2][0]+=data_train.loc[data,\"Age\"]\n                age_in[2][1]+=1\n        elif \"Dr.\" in data_train.loc[data,\"Name\"]:\n            if not math.isnan(data_train.loc[data,\"Age\"]) :\n                age_in[3][0]+=data_train.loc[data,\"Age\"]\n                age_in[3][1]+=1\n        elif \"Mrs.\" in data_train.loc[data,\"Name\"]:\n            if not math.isnan(data_train.loc[data,\"Age\"]) :\n                age_in[4][0]+=data_train.loc[data,\"Age\"]\n                age_in[4][1]+=1\n    return age_in\n\ncount_every_call_mid(data_train,age_in)\nage_median = data_train.Age.median()\nave=[0,0,0,0,0]\nfor i in range(0,5):\n    ave[i]=age_in[i][0]/age_in[i][1]\n    print(ave[i])#Mr./Miss./Master./Dr./Mrs.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5cb8d5b6d9e539c4dc4347ef45a62ddbe8af8498"
      },
      "cell_type": "markdown",
      "source": "通过统计结果表明，每个称呼的年龄和全称呼结果相差较大。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aac3a7c7e3f19cc09c0fc489ed31a7bfd95486f2"
      },
      "cell_type": "code",
      "source": "#将各称呼年龄平均年龄填充，非常用称呼用平均年龄填充\ndef replace_age_by_mid_of_call(dataset):\n    for data in dataset.index:\n        #print(data_train.loc[data,\"Name\"])\n        if math.isnan(dataset.loc[data,\"Age\"]) :\n            if \"Mr.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[0]\n            elif \"Miss.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[1]\n            elif \"Master.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[2]\n            elif \"Dr.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[3]\n            elif \"Mrs.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[4]\n            else:\n                dataset.loc[data,\"Age\"]=age_median\nreplace_age_by_mid_of_call(data_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "071ec6d483431aa0c5fdcbf1c45b93c2f0cb525f"
      },
      "cell_type": "markdown",
      "source": "### 方法三：将预测样本集和训练样本集在一起处理。\n因为在不涉及结果，而对单个特征进行处理时，可以将所有集合看作一个新的样本。通过这个“新样本集合”来预测缺失值。"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "ca750f01ef1718a8cff1fa0f0fb2f4370ee002fe"
      },
      "cell_type": "code",
      "source": "#此处对于pandas读取的文件和列表有不同的处理格式\n#统计整体内除了基本称呼\"Mr./Miss./Master./Dr./Mrs.\"以外的称呼占总体称呼的多少\ncount = 0\nfor dataset in combine:\n    count = check_if_the_name_including_reguler(dataset,count)\n    print(\"\\n\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10f077d694a163f86928be23c65a43a6a9f2ad61"
      },
      "cell_type": "markdown",
      "source": "可见，在总体样本中，除了基本称呼以外并不多。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11b39b919667043929e15c8b749a9d3126c46575"
      },
      "cell_type": "code",
      "source": "#统计所有样本中，每种称谓的平均年龄：\nage_in = []   #Mr./Miss./Master./Dr./Mrs.\nfor i in range(0,5):\n    age_in.insert(0,[0,0])\nfor dataset in combine:\n    age_in = count_every_call_mid(dataset,age_in)\nage_median = data_train.Age.median()\nave=[0,0,0,0,0]\nfor i in range(0,5):\n    ave[i]=age_in[i][0]/age_in[i][1]\n    print(ave[i])#Mr./Miss./Master./Dr./Mrs.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b3cfbacb8cc97aa51f3d4c39ab86c74595aefc6"
      },
      "cell_type": "markdown",
      "source": "由此对比，可见，五个称呼的平均值均有不同程度的修正。再用新的修正值填充空缺Age值。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e958912424ce876c9f78cb767e18a557f75bb280"
      },
      "cell_type": "code",
      "source": "#用新的平均值填充\ndef replace_age_by_mid_of_call(dataset):\n    for data in dataset.index:\n        #print(data_train.loc[data,\"Name\"])\n        if math.isnan(dataset.loc[data,\"Age\"]) :\n            if \"Mr.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[0]\n            elif \"Miss.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[1]\n            elif \"Master.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[2]\n            elif \"Dr.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[3]\n            elif \"Mrs.\" in dataset.loc[data,\"Name\"]:\n                dataset.loc[data,\"Age\"]=ave[4]\n            else:\n                dataset.loc[data,\"Age\"]=age_median\n\nfor dataset in combine:\n    replace_age_by_mid_of_call(dataset)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4f6fc3a79d59af061cd1a00b0c9c1c5a0d70dd5"
      },
      "cell_type": "code",
      "source": "#检查样本是否被填充\ndata_test.shape[0] - data_test.count()\n#检查样本是否被填充\n#data_train.shape[0] - data_train.count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2bfbe05163db70c64d50bb97f744f3585f513577"
      },
      "cell_type": "markdown",
      "source": "## Cabin处理"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9599ad69accbda15a081d1701be3ebac8b7c30e1"
      },
      "cell_type": "code",
      "source": "#方法一：直接丢弃该特征\n#data_train = data_train.drop(['Cabin'],axis=1)\n#有时候运行两次会出错，因为同一个特征无法丢弃两次",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c6062fd658cb25ed2a6067892366b5257455b85"
      },
      "cell_type": "code",
      "source": "#方法二：利用\ndef replaceCabin(data):\n    data['Cabin'] = data['Cabin'].fillna('X')\n    data['Cabin'] = data['Cabin'].apply(lambda x: str(x)[0])\n    data['Cabin'] = data['Cabin'].replace(['A', 'D', 'E', 'T'], 'M')\n    data['Cabin'] = data['Cabin'].replace(['B', 'C'], 'H')\n    data['Cabin'] = data['Cabin'].replace(['F', 'G'], 'L')\n    data['Cabin'] = data['Cabin'].map({'X': 0, 'L': 1, 'M': 2, 'H': 3}).astype(int)\n\n# def replaceCabin(data):\n#     data['Cabin'] = data['Cabin'].fillna('X')\n#     data['Cabin'] = data['Cabin'].apply(lambda x: str(x)[0])\n# #     data['Cabin'] = data['Cabin'].replace(['A', 'D', 'E', 'T'], 'M')\n# #     data['Cabin'] = data['Cabin'].replace(['B', 'C'], 'H')\n# #     data['Cabin'] = data['Cabin'].replace(['F', 'G'], 'L')\n#     data['Cabin'] = data['Cabin'].map({'X': 0, 'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7,'T':8}).astype(int) \n\nfor dataset in combine:\n    replaceCabin(dataset)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2158881ca713e787d44cfd6b96e453245f928d5c"
      },
      "cell_type": "markdown",
      "source": "## Sex处理"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2e20d6b8cd9b1dc92e5f28cd54b25e7e347606a"
      },
      "cell_type": "code",
      "source": "# for dataset in combine:\n#     print(dataset)\n#     if 'male' not in dataset['Sex']:\n#          print(dataset['Sex'])\n#     dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n\n# data_train.head()\ndata_train.replace({'Sex':{'female':1,'male':2}},inplace=True)\n# #处理预测样本集\ndata_test.replace({'Sex':{'female':1,'male':2}},inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "692becaf71bd257ab90656648d2e3458578ec048"
      },
      "cell_type": "markdown",
      "source": "## Fare处理\n  因为Fare仅在预测样本中缺失，因此，不能直接丢弃。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a27b44f6e95e76d25500219623b22cdbefb465c8"
      },
      "cell_type": "code",
      "source": "#方法一：选择平均值填充\nfare_median = data_test.Fare.median()\ndata_test['Fare'].fillna(data_test['Fare'].dropna().median(), inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b5fb9f6f029d7a35dba41f116a9a6f9cf615e0e"
      },
      "cell_type": "code",
      "source": "#抽取前五个样本，查看是否所有特征均得到合适处理\ndata_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7d8b4aa63715630c2cb1e77c326ac68f2a83706"
      },
      "cell_type": "code",
      "source": "#检查预测样本集是否对特征进行了处理\ndata_test.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "59800837bb71a30c7af46ce04687cc1d9153906f"
      },
      "cell_type": "markdown",
      "source": "## Tickes处理"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca6b98a2c1255a46dbb3b70cbf66da514cf8b24c"
      },
      "cell_type": "code",
      "source": "# Ticket\ndf = data_train['Ticket'].value_counts()\ndf = pd.DataFrame(df)\ndf = df[df['Ticket'] > 1]\ndf_ticket = df.index.values        #共享船票的票号\ntickets = data_train.Ticket.values    #所有的船票\nresult = []\nfor ticket in tickets:\n    if ticket in df_ticket:\n        ticket = 1\n    else:\n        ticket = 0                 #遍历所有船票，在共享船票里面的为1，否则为0\n    result.append(ticket)\nresults = pd.DataFrame(result)\nresults.columns = ['Ticket_Count']\ndata_train = pd.concat([data_train, results], axis=1)\n\ndf = data_test['Ticket'].value_counts()\ndf = pd.DataFrame(df)\ndf = df[df['Ticket'] > 1]\ndf_ticket = df.index.values        #共享船票的票号\ntickets = data_test.Ticket.values    #所有的船票\nresult = []\nfor ticket in tickets:\n    if ticket in df_ticket:\n        ticket = 1\n    else:\n        ticket = 0                 #遍历所有船票，在共享船票里面的为1，否则为0\n    result.append(ticket)\nresults = pd.DataFrame(result)\nresults.columns = ['Ticket_Count']\ndata_test = pd.concat([data_test, results], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e68f08323b9976fdf8304647caa22b3755381f86"
      },
      "cell_type": "markdown",
      "source": "## Cabin处理"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aac961f0e07905588ae334fc19b9a3acb0f8afe2"
      },
      "cell_type": "code",
      "source": "# Cabin\nfor dataset in combine:\n    dataset.loc[(dataset.Cabin.isnull()), 'Cabin'] = 0\n    dataset.loc[(dataset.Cabin.notnull()), 'Cabin'] = 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7a5db7547ad69e2378af93502f7d25c0072c8a0c"
      },
      "cell_type": "markdown",
      "source": "## Embarked处理"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "371e80747375d86b69950983a30a9b2c00b3d652"
      },
      "cell_type": "code",
      "source": "#方法一：因为只有两个，直接丢去\ndata_train = data_train.dropna(subset=['Embarked'])\n# for data in combine:\n#     data.loc[data['Embarked']=='S']=1\n#     data.loc[data['Embarked']=='C']=2\n#     data.loc[data['Embarked']=='Q']=2\ndata_train = data_train.replace({'Embarked':{'S':1,'C':2,'Q':3}})\ndata_test = data_test.replace({'Embarked':{'S':1,'C':2,'Q':3}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a430c2ea359327983f3b6dabdb5ea6634544d4a"
      },
      "cell_type": "code",
      "source": "data_test.shape[0] - data_test.count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5fe4bd6cd7d59af4dcd6903734486fa0c92e66f3"
      },
      "cell_type": "code",
      "source": "data_train.shape[0] - data_train.count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2367a6c08b8e0ce27977a4b1ef1faed0e1e7db4d"
      },
      "cell_type": "markdown",
      "source": "## 特征"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e0ba592140026c1d00f549cd777d1a9c2089bff"
      },
      "cell_type": "code",
      "source": "#特征\ndata_test_X  = data_test[['Pclass', 'Sex', 'Age','SibSp', 'Parch', 'Fare', 'Embarked','Ticket_Count','Cabin']]\nX_train = data_train[['Pclass', 'Sex', 'Age','SibSp', 'Parch', 'Fare', 'Embarked','Ticket_Count','Cabin']]\nY_train = data_train['Survived']\nX_test = data_test_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e25cdd9258607371a24280d65823ad13ed7854f"
      },
      "cell_type": "code",
      "source": "#模型比较\n#随机森林\nrandom_forest = RandomForestClassifier(n_estimators=300, max_depth=5, criterion='entropy')\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a49a92a40fa10237f719e54d69283b587ce4b52d"
      },
      "cell_type": "code",
      "source": "#模型写出\nsubmission = pd.DataFrame({\n        \"PassengerId\": data_test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}